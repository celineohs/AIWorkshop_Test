{
  "step": 2,
  "name": "preprocessing",
  "timestamp": "2026-01-30 15:20",
  "results": {
    "qc": {
      "min_responses": 10,
      "low_response_count": 1,
      "straight_lining_count": 31,
      "flagged_count": 32,
      "valid_n": 23647
    },
    "scores": {
      "calculated_scales": [
        "NEO_O",
        "NEO_C",
        "NEO_E",
        "NEO_A",
        "NEO_N",
        "Ideology",
        "Honesty_Humility"
      ],
      "valid_n": {
        "NEO_O": 23399,
        "NEO_C": 23417,
        "NEO_E": 23357,
        "NEO_A": 23437,
        "NEO_N": 23371,
        "Ideology": 11825,
        "Honesty_Humility": 12828
      },
      "output_file": "data/processed/sapa_scores.csv"
    }
  },
  "notes": [
    "QC: 32명 제외 (응답부족 1 + straight-lining 31)",
    "Big Five + Ideology + Honesty-Humility 계산 완료"
  ]
}
