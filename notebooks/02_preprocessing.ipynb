{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02. 전처리 (Preprocessing)\n",
        "\n",
        "SAPA 데이터를 전처리하고 성격 척도 점수를 계산합니다.\n",
        "\n",
        "## 학습 목표\n",
        "- Quality Control (QC): 응답 부족 및 Straight-lining 제외\n",
        "- 역채점 처리 방법 이해\n",
        "- Big Five, Ideology, Honesty-Humility 점수 계산\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 설치 (처음 한 번만 실행)\n",
        "%pip install pandas numpy scipy -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "작업 폴더: /Users/serinoh/serin-oh/safa\n"
          ]
        }
      ],
      "source": [
        "# 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import os\n",
        "\n",
        "# 상위 폴더로 이동해서 데이터 접근\n",
        "if os.path.basename(os.getcwd()) == 'notebooks':\n",
        "    os.chdir('..')\n",
        "print(f'작업 폴더: {os.getcwd()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 데이터 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "응답자 수: 23,679\n",
            "변수 수: 719\n",
            "채점 키: 696개 문항, 131개 척도\n"
          ]
        }
      ],
      "source": [
        "# SAPA 응답 데이터 로드\n",
        "df = pd.read_csv('data/raw/sapa_data.csv')\n",
        "keys = pd.read_csv('data/raw/superKey696.csv', index_col=0)\n",
        "\n",
        "print(f'응답자 수: {len(df):,}')\n",
        "print(f'변수 수: {len(df.columns)}')\n",
        "print(f'채점 키: {keys.shape[0]}개 문항, {keys.shape[1]}개 척도')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "성격 문항 수: 696개\n"
          ]
        }
      ],
      "source": [
        "# 성격 문항 컬럼 추출\n",
        "item_cols = [col for col in df.columns if col.startswith('q_')]\n",
        "print(f'성격 문항 수: {len(item_cols)}개')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Quality Control (QC)\n",
        "\n",
        "다음 기준으로 응답자를 제외합니다:\n",
        "1. **응답 부족**: 10개 미만의 문항에 응답한 경우\n",
        "2. **Straight-lining**: 모든 응답이 동일한 값인 경우 (무응답 제외)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "응답 부족 (10개 미만): 1명\n",
            "평균 응답 문항 수: 86.1개\n"
          ]
        }
      ],
      "source": [
        "# QC 1: 응답 부족 (10개 미만)\n",
        "responses_per_person = df[item_cols].notna().sum(axis=1)\n",
        "insufficient_responses = responses_per_person < 10\n",
        "\n",
        "print(f'응답 부족 (10개 미만): {insufficient_responses.sum():,}명')\n",
        "print(f'평균 응답 문항 수: {responses_per_person.mean():.1f}개')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Straight-lining: 31명\n"
          ]
        }
      ],
      "source": [
        "# QC 2: Straight-lining 감지\n",
        "# 각 응답자의 응답값 중 고유값 개수 확인 (결측 제외)\n",
        "def detect_straightlining(row):\n",
        "    \"\"\"응답이 모두 같은 값인지 확인 (결측 제외)\"\"\"\n",
        "    non_missing = row.dropna()\n",
        "    if len(non_missing) == 0:\n",
        "        return False  # 모두 결측이면 straight-lining 아님\n",
        "    return non_missing.nunique() == 1  # 고유값이 1개면 straight-lining\n",
        "\n",
        "straightlining = df[item_cols].apply(detect_straightlining, axis=1)\n",
        "print(f'Straight-lining: {straightlining.sum():,}명')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 제외 인원: 32명\n",
            "유효 응답자 수: 23,647명\n",
            "\n",
            "필터링 후 데이터 크기: (23647, 719)\n"
          ]
        }
      ],
      "source": [
        "# QC 통합: 제외할 응답자\n",
        "exclude = insufficient_responses | straightlining\n",
        "print(f'총 제외 인원: {exclude.sum():,}명')\n",
        "print(f'유효 응답자 수: {(~exclude).sum():,}명')\n",
        "\n",
        "# 유효한 응답자만 필터링\n",
        "df_valid = df[~exclude].copy()\n",
        "print(f'\\n필터링 후 데이터 크기: {df_valid.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 척도 점수 계산 함수\n",
        "\n",
        "채점 키를 사용하여 척도 점수를 계산합니다.\n",
        "- `1`: 정채점\n",
        "- `-1`: 역채점 (7 - 원점수, 6점 척도)\n",
        "- `0`: 해당 없음\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_scale_score(df, keys, scale_name):\n",
        "    \"\"\"\n",
        "    채점 키를 사용해 척도 점수 계산\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        응답 데이터 (문항 컬럼 포함)\n",
        "    keys : DataFrame\n",
        "        채점 키 매트릭스 (index=문항명, columns=척도명)\n",
        "    scale_name : str\n",
        "        계산할 척도명 (예: 'NEO_E')\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    Series\n",
        "        각 응답자의 척도 점수\n",
        "    \"\"\"\n",
        "    # 해당 척도에 속하는 문항 찾기\n",
        "    scale_items = keys.index[keys[scale_name] != 0].tolist()\n",
        "    weights = keys.loc[scale_items, scale_name]\n",
        "    \n",
        "    # 데이터에 있는 문항만 필터링\n",
        "    available_items = [q for q in scale_items if q in df.columns]\n",
        "    \n",
        "    if not available_items:\n",
        "        return pd.Series([np.nan] * len(df), index=df.index)\n",
        "    \n",
        "    # 역채점 적용 (6점 척도: 7 - 원점수)\n",
        "    subset = df[available_items].copy()\n",
        "    for item in available_items:\n",
        "        if weights[item] == -1:\n",
        "            subset[item] = 7 - subset[item]\n",
        "    \n",
        "    # 평균 계산 (결측 무시)\n",
        "    return subset.mean(axis=1, skipna=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Big Five 점수 계산\n",
        "\n",
        "NEO Big Five 성격 요인 점수를 계산합니다:\n",
        "- Openness (개방성, NEO_O)\n",
        "- Conscientiousness (성실성, NEO_C)\n",
        "- Extraversion (외향성, NEO_E)\n",
        "- Agreeableness (우호성, NEO_A)\n",
        "- Neuroticism (신경증, NEO_N)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Big Five 점수 계산 완료\n",
            "점수 데이터 크기: (23647, 6)\n"
          ]
        }
      ],
      "source": [
        "# 점수 저장용 DataFrame 초기화\n",
        "scores = pd.DataFrame()\n",
        "scores['RID'] = df_valid['RID'].values  # .values로 index 정보 제거\n",
        "\n",
        "# Big Five 점수 계산\n",
        "scores['NEO_Openness'] = calculate_scale_score(df_valid, keys, 'NEO_O').values\n",
        "scores['NEO_Conscientiousness'] = calculate_scale_score(df_valid, keys, 'NEO_C').values\n",
        "scores['NEO_Extraversion'] = calculate_scale_score(df_valid, keys, 'NEO_E').values\n",
        "scores['NEO_Agreeableness'] = calculate_scale_score(df_valid, keys, 'NEO_A').values\n",
        "scores['NEO_Neuroticism'] = calculate_scale_score(df_valid, keys, 'NEO_N').values\n",
        "\n",
        "print('Big Five 점수 계산 완료')\n",
        "print(f'점수 데이터 크기: {scores.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Big Five 점수 요약 ===\n",
            "                           N  Mean    SD  Min  Max\n",
            "NEO_Openness           23399  4.31  0.83  1.0  6.0\n",
            "NEO_Conscientiousness  23417  4.23  0.86  1.0  6.0\n",
            "NEO_Extraversion       23357  3.87  0.92  1.0  6.0\n",
            "NEO_Agreeableness      23437  4.23  0.82  1.0  6.0\n",
            "NEO_Neuroticism        23371  3.35  0.98  1.0  6.0\n"
          ]
        }
      ],
      "source": [
        "# Big Five 점수 요약 통계\n",
        "big_five_cols = ['NEO_Openness', 'NEO_Conscientiousness', 'NEO_Extraversion', \n",
        "                 'NEO_Agreeableness', 'NEO_Neuroticism']\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    'N': scores[big_five_cols].notna().sum(),\n",
        "    'Mean': scores[big_five_cols].mean(),\n",
        "    'SD': scores[big_five_cols].std(),\n",
        "    'Min': scores[big_five_cols].min(),\n",
        "    'Max': scores[big_five_cols].max()\n",
        "})\n",
        "print('\\n=== Big Five 점수 요약 ===')\n",
        "print(summary.round(2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Ideology (이념) 점수 계산\n",
        "\n",
        "보수적 이념 점수는 다음 공식으로 계산합니다:\n",
        "> **Ideology** = mean( z(MPQ_Traditionalism), z(NEO_Liberalism) × -1 )\n",
        "\n",
        "- MPQ Traditionalism (MPQtr): 보수성 척도\n",
        "- NEO Liberalism (NEOo6): 개방성 하위 요인, 역채점하여 보수성 지표로 변환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ideology 점수 계산 완료\n",
            "\n",
            "Ideology 요약:\n",
            "  N: 11825\n",
            "  Mean: 0.033\n",
            "  SD: 0.969\n"
          ]
        }
      ],
      "source": [
        "# Ideology 계산을 위한 하위 척도 점수\n",
        "scores['MPQ_Traditionalism'] = calculate_scale_score(df_valid, keys, 'MPQtr').values\n",
        "scores['NEO_Liberalism'] = calculate_scale_score(df_valid, keys, 'NEOo6').values\n",
        "\n",
        "# z-score 계산 함수\n",
        "def z_score(series):\n",
        "    \"\"\"표준화 (z-score)\"\"\"\n",
        "    return (series - series.mean()) / series.std()\n",
        "\n",
        "# Ideology 점수 계산 (z-score 후 평균)\n",
        "z_mpq = z_score(scores['MPQ_Traditionalism'])\n",
        "z_neo_lib = z_score(scores['NEO_Liberalism'])\n",
        "scores['Ideology'] = (z_mpq + z_neo_lib * -1) / 2\n",
        "\n",
        "print('Ideology 점수 계산 완료')\n",
        "print(f'\\nIdeology 요약:')\n",
        "print(f'  N: {scores[\"Ideology\"].notna().sum()}')\n",
        "print(f'  Mean: {scores[\"Ideology\"].mean():.3f}')\n",
        "print(f'  SD: {scores[\"Ideology\"].std():.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Honesty-Humility (정직-겸손) 점수 계산\n",
        "\n",
        "Honesty-Humility 점수는 다음 공식으로 계산합니다:\n",
        "> **H-H** = mean( z(NEO_Morality), z(NEO_Modesty), z(HEXACO_H) )\n",
        "\n",
        "- NEO Morality (NEOa2): 도덕성\n",
        "- NEO Modesty (NEOa4): 겸손함\n",
        "- HEXACO Honesty-Humility (HEXACO_H): 정직-겸손\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Honesty-Humility 점수 계산 완료\n",
            "\n",
            "Honesty-Humility 요약:\n",
            "  N: 12828\n",
            "  Mean: -0.003\n",
            "  SD: 0.727\n"
          ]
        }
      ],
      "source": [
        "# Honesty-Humility 계산을 위한 하위 척도 점수\n",
        "scores['NEO_Morality'] = calculate_scale_score(df_valid, keys, 'NEOa2').values\n",
        "scores['NEO_Modesty'] = calculate_scale_score(df_valid, keys, 'NEOa4').values\n",
        "scores['HEXACO_H'] = calculate_scale_score(df_valid, keys, 'HEXACO_H').values\n",
        "\n",
        "# Honesty-Humility 점수 계산 (z-score 후 평균)\n",
        "z_morality = z_score(scores['NEO_Morality'])\n",
        "z_modesty = z_score(scores['NEO_Modesty'])\n",
        "z_hexaco_h = z_score(scores['HEXACO_H'])\n",
        "scores['Honesty_Humility'] = (z_morality + z_modesty + z_hexaco_h) / 3\n",
        "\n",
        "print('Honesty-Humility 점수 계산 완료')\n",
        "print(f'\\nHonesty-Humility 요약:')\n",
        "print(f'  N: {scores[\"Honesty_Humility\"].notna().sum()}')\n",
        "print(f'  Mean: {scores[\"Honesty_Humility\"].mean():.3f}')\n",
        "print(f'  SD: {scores[\"Honesty_Humility\"].std():.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 최종 점수 요약\n",
        "\n",
        "모든 척도 점수의 요약 통계를 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 최종 점수 요약 ===\n",
            "                           N   Mean     SD    Min    Max\n",
            "NEO_Openness           23399  4.308  0.827  1.000  6.000\n",
            "NEO_Conscientiousness  23417  4.233  0.855  1.000  6.000\n",
            "NEO_Extraversion       23357  3.868  0.922  1.000  6.000\n",
            "NEO_Agreeableness      23437  4.225  0.816  1.000  6.000\n",
            "NEO_Neuroticism        23371  3.355  0.979  1.000  6.000\n",
            "Ideology               11825  0.033  0.969 -1.527  1.675\n",
            "Honesty_Humility       12828 -0.003  0.727 -2.962  1.642\n"
          ]
        }
      ],
      "source": [
        "# 최종 점수 컬럼\n",
        "final_score_cols = big_five_cols + ['Ideology', 'Honesty_Humility']\n",
        "\n",
        "final_summary = pd.DataFrame({\n",
        "    'N': scores[final_score_cols].notna().sum(),\n",
        "    'Mean': scores[final_score_cols].mean(),\n",
        "    'SD': scores[final_score_cols].std(),\n",
        "    'Min': scores[final_score_cols].min(),\n",
        "    'Max': scores[final_score_cols].max()\n",
        "})\n",
        "\n",
        "print('=== 최종 점수 요약 ===')\n",
        "print(final_summary.round(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 결과 저장\n",
        "\n",
        "계산된 점수를 CSV 파일로 저장합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장 완료: data/processed/sapa_scores.csv\n",
            "점수 계산된 응답자 수: 23,647명\n",
            "저장된 척도: 7개\n",
            "\n",
            "척도 목록:\n",
            "  - NEO_Openness\n",
            "  - NEO_Conscientiousness\n",
            "  - NEO_Extraversion\n",
            "  - NEO_Agreeableness\n",
            "  - NEO_Neuroticism\n",
            "  - Ideology\n",
            "  - Honesty_Humility\n"
          ]
        }
      ],
      "source": [
        "# processed 폴더가 없으면 생성\n",
        "os.makedirs('data/processed', exist_ok=True)\n",
        "\n",
        "# 점수 저장\n",
        "output_path = 'data/processed/sapa_scores.csv'\n",
        "scores.to_csv(output_path, index=False)\n",
        "\n",
        "print(f'저장 완료: {output_path}')\n",
        "print(f'점수 계산된 응답자 수: {len(scores):,}명')\n",
        "print(f'저장된 척도: {len(final_score_cols)}개')\n",
        "print(f'\\n척도 목록:')\n",
        "for col in final_score_cols:\n",
        "    print(f'  - {col}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. QC 리포트 요약\n",
        "\n",
        "전처리 과정에서 제외된 응답자 정보를 요약합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== QC 리포트 ===\n",
            "원본 응답자 수: 23,679명\n",
            "응답 부족 제외 (10개 미만): 1\n",
            "Straight-lining 제외: 31\n",
            "총 제외 인원: 32\n",
            "최종 유효 응답자 수: 23,647명\n",
            "유효 응답자 비율: 99.9%\n"
          ]
        }
      ],
      "source": [
        "qc_summary = {\n",
        "    '원본 응답자 수': len(df),\n",
        "    '응답 부족 제외 (10개 미만)': insufficient_responses.sum(),\n",
        "    'Straight-lining 제외': straightlining.sum(),\n",
        "    '총 제외 인원': exclude.sum(),\n",
        "    '최종 유효 응답자 수': len(df_valid),\n",
        "    '유효 응답자 비율': f\"{(~exclude).sum() / len(df) * 100:.1f}%\"\n",
        "}\n",
        "\n",
        "print('=== QC 리포트 ===')\n",
        "for key, value in qc_summary.items():\n",
        "    if isinstance(value, int):\n",
        "        print(f'{key}: {value:,}명')\n",
        "    else:\n",
        "        print(f'{key}: {value}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
